#!/bin/bash


PURPOSE=baseline
JUDGECLASS="oldreut"

CORPLIST=("oldreut")
SOFIA="/home/jean/Documents/tar-toolkit-core-copy/sofia-ml-read-only/sofia-ml"

: '
    Percorre cada item listado em
    CORPLIST.
'
for CORP in "${CORPLIST[@]}"; do

    pushd Corpus # pushd <dir> é semelhante à cd <dir>

    ./dofast4 "$CORP"

    cp "$CORP".df ../"$CORP".df

    cp "$CORP".svm.fil ../"$CORP".svm.fil

    popd # popd é semelhante ao cd ..

    : '
        IFS significa Internal Field Separator (separador interno de campos) e
            é utilizado pelo bash para dizer como fazer a separação de palavras,
            ou seja, como identificar palavras (o valor padrã é um espaço em branco " ").

        read <line> permite ler um arquivo linha por linha. -r diz ao bash para não
            permitir que barra invevrtida escape caracteres. IFS="" faz com que
            espaços em brancos no começo e no fim não sejam removidos durante a leitura.

        Sintaxe para leitura de arquivos linha por linha:
            while IFS="" read -r line; do
                <comandos que irão tratar $line>
            done < input_file
    '
    while IFS='' read -r line || [[ -n $line ]]; do # arquivo de entrada: judgement/$CORP.topic.stemming.txt

        : '
        read -ra TEXT atribui o conteúdo de $line a um array chamado TEXT. Neste caso,
            os elementos da linha são separados em cada ":" e cada um vira um elemento do array.
        '
        IFS=':' read -ra TEXT <<< "$line"

        TOPIC="${TEXT[0]}"
        QUERY="${TEXT[1]}"

        echo "$TOPIC"
        echo "$QUERY"

        rm -rf result/"$PURPOSE"/"$CORP"/"$TOPIC"/
        mkdir -p result/"$PURPOSE"/"$CORP"/
        mkdir -p result/dump/"$PURPOSE"/"$CORP"/

        rm -rf $TOPIC
        mkdir $TOPIC


        : '
            wc -l mostra o número de linhas de um arquivo. Assim, "N" armazena
                o número de linhas do arquivo "$CORP.svm.fil".
        '
        echo `wc -l < "$CORP".svm.fil` > N

        pushd $TOPIC

        echo "$QUERY" > "$TOPIC".seed.doc

        : '
            cut é utilizado para selecionar (cortar) partes de um arquivo.

                -f permite selecionar com base em um campo (neste caso
                o primeiro: -f1 ou -f 1).

                -d especifica o delimitador, utilizado para separar os campos.

                cut -d " " -f 1 forma campos dividindo cada linha nos espaços em
                branco e seleciona a primeira coluna.

            sed é um editor (não interativo) que permite, dentre outras coisas,
                realizar substituições em uma entrada de texto.

                -e <script> diz para executar <script>. Neste caso não é necessário
                pois há apenas um script/comando.

                em "s/.*/& &/", s informa que será executada uma substituição no texto
                de entrada. .* é o pattern que deve ser substituido pelo pattern & &.
                    .* representa qualquer caracter exceto quebra de linha, ou seja,
                    permite selecionar uma linha inteira.

                    & representa toda a string encontrada.

                então sed "s/.*/& &/" duplica o conteúdo de cada linha
                de um arquivo.
        '

        cut -d' ' -f1 ../$CORP.svm.fil | sed -e 's/.*/& &/' > docfil
        cut -d' ' -f1 docfil | cat -n > docfils


        touch rel.$TOPIC.fil
        touch prel.$TOPIC

        rm -rf prevalence.rate
        touch prevalence.rate

        rm -rf rel.rate
        touch rel.rate

        rm -f new[0-9][0-9].$TOPIC tail[0-9][0-9].$TOPIC self*.$TOPIC gold*.$TOPIC
        touch new00.$TOPIC


        : '
            NDOCS armazena a quantidade de linhas dentro de docfils, que corresponde
                ao número de documentos.
        '
        NDOCS=`cat docfils | wc -l`
        NDUN=0
        L=1
        R=100
        export LAMBDA=0.0001

        : '
            $TOPIC.seed.doc armazena a query para $TOPIC
        '

        cp $TOPIC.seed.doc ../$TOPIC.seed.doc

        popd

        ./dofeaturesseed4 $TOPIC.seed.doc $TOPIC $CORP

        pushd $TOPIC

        : '
            sed -e "s/[^ ]*/0/ <file> substitui a primeira coluna de <file> para 0"
        '

        sed -e 's/[^ ]*/0/' ../$CORP.svm.fil | ../dosplit
        sed -e 's/[^ ]*/1/' svm.$TOPIC.seed.doc.fil > $TOPIC.synthetic.seed


        for x in 0 1 2 3 4 5 6 7 8 9 ; do

            for y in 0 1 2 3 4 5 6 7 8 9 ; do

                if [ $NDUN -lt $NDOCS ] ; then
                    export N=$x$y
                    cp $TOPIC.synthetic.seed trainset

                    cut -f2 docfils | sort -R | head -$R | sort | join - ../$CORP.svm.fil | sed -e's/[^ ]*/-1/' >> trainset

                    cat new[0-9][0-9].$TOPIC > seed
                    cat seed | sort | join - rel.$TOPIC.fil | sed -e 's/^/1 /' > x
                    cat seed | sort | join -v1 - rel.$TOPIC.fil | sort -R | head -50000 | sed -e 's/^/-1 /' >> x

                    sort -k2 x | join -12 - ../$CORP.svm.fil | cut -d' ' -f2- | sort -n >> trainset

                    : '
                        grep -E <pattern> <file> busca <pattern> dentro de <file> e mostra
                            as linhas que possuem um padrão;
                            * grep -E "^1\b" trainset retorna todas as linhas que começam com
                                1 (e que tenham um espaço após o 1);
                    '

                    # Calculate relevant documents prevalence rate in the traning set

                    RELTRAINDOC=`grep -E "^1\b" trainset | wc -l` # Número de documentos relevantes em trainset

                    NOTRELTRAINDOC=`grep -E "^-1\b" trainset | wc -l` # Número de docs não relevantes em trainset

                    : '
                        bc é utilizado para realizar cálculos matemáticos
                    '

                    PREVALENCERATE=`echo "scale=4; $RELTRAINDOC / ($RELTRAINDOC + $NOTRELTRAINDOC)" | bc` # taxa de documentos
                                                                                                          # relevantes

                    echo $RELTRAINDOC $NOTRELTRAINDOC $PREVALENCERATE >> prevalence.rate


                    : '
                        Parametros do sofia-ml:
                            * --learner_type logreg-pegasos: Utiliza regressão logística com atualizações
                                do Pegasos. Pegasos SVM é um algoritmo de aprendizagem;
                            * --loop_type roc: --loop_type controla como os exemplos são selecionados; 
                            * --lambda: parametro de regularização do Pegasos;
                            * --iterations: número de passos do gradiente estocástico (stochastic gradient);
                            * --dimensionality: dimensão do dataset - índice do maior feature de treino + 1;

                            * --test_file: especifica o arquivo a ser usado para teste;
                            * --model_in: lê o modelo do arquivo especificado (o modelo será utilizado para treino/teste);
                            * --results_file: especifica o arquivo onde os resultados de teste (quando --test_file for especificado) serão escritos;
                    '

                    $SOFIA --learner_type logreg-pegasos --loop_type roc --lambda $LAMBDA --iterations 200000 --training_file trainset --dimensionality 9300000 --model_out svm_model

                    : '
                        $? armazena o estatus de saída do comando executado mais recentemente:
                            0 se o comando executou normalmente, outro valor caso contrário.
                    '

                    RES=$?
                    echo $RES

                    # se o modelo foi treinado com sucesso, ele será testado
                    if [ "$RES" -eq "0" ] ; then 
                        for z in svm.test.* ; do
                            $SOFIA --test_file $z --dimensionality 9300000 --model_in svm_model --results_file pout.$z
                        done

                    else
                        rm -f pout.svm.test.*
                        cut -f2 docfils | sort -R | cat -n | sort -k2 | sed -e 's/ */-/' > pout.svm.test.1
                    fi

                    : '
                        join -o permite espicificar a ordem dos campos na saída
                          - join -o2.2,1.2 está especificando que a saída deverá conter o 
                            segundo campo do segundo arquivo (2.2) seguido do segundo campo do 
                            primeiro arquivo (1.2)

                        join -t permite especificar o separador
                    '

                    cut -f1 pout.svm.test.* | ../fixnum | cat -n | join -o2.2,1.2 -t$'\t' - docfils > inlr.out
                    sort seed | join -v2 - inlr.out | sort -rn -k2 | cut -d' ' -f1 > new$N.$TOPIC
                    cat new[0-9][0-9].$TOPIC > x

                    if [ "$N" != "99" ] ; then
                        # adiciona as primeiras $L linhas de new$N.$TOPIC para y e depois denovo para new$N.$TOPIC
                        head -$L new$N.$TOPIC > y ; mv y new$N.$TOPIC
                    fi

                    : '
                        x armazena new($N - 1).$TOPIC
                    '

                    # judgefile é o arquivo que diz quais docs são os positivos
                    python ../doJudgementMain.py --topic=$TOPIC --judgefile=../judgement/qrels.$JUDGECLASS.list --input=new$N.$TOPIC --output=rel.$TOPIC.Judged.doc.list --record=$TOPIC.record.list

                    # o arquivo rel.$TOPIC.Judged.doc.list contém os docs relevantes

                    cat rel.$TOPIC.Judged.doc.list >> rel.$TOPIC.fil
                    cat rel.$TOPIC.Judged.doc.list > rel.$TOPIC.$N.Judged.doc.list

                    : '
                        rel.$TOPIC.fil armazena todos os resultados da execução de doJudgementMain.py
                        enquanto rel.$TOPIC.$N.Judged.doc.list armazena o resultado da última execução
                    '

                    RELFINDDOC=`wc -l < rel.$TOPIC.Judged.doc.list`
                    # scale=4 diz ao bc para usar 4 casas decimais
                    RELRATE=`echo "scale=4; $RELFINDDOC / $L" | bc`
                    CURRENTREL=`wc -l < rel.$TOPIC.fil` # número de relevantes
                    echo $RELFINDDOC $L $RELRATE $CURRENTREL >> rel.rate

                    # adiciona ' 1' ao final de cada linha de rel.$TOPIC.fil e manda o resultado para prel.$TOPIC
                    sort rel.$TOPIC.fil | sed -e 's/$/ 1/' > prel.$TOPIC

                    cut -d' ' -f1 prel.$TOPIC > rel.$TOPIC.fil

                    NDUN=$((NDUN+L))
                    L=$((L+(L+9)/10))
                fi
            done
        done

        rm -rf svm.test.*
        popd

        mv $TOPIC result/"$PURPOSE"/"$CORP"/$TOPIC
        rm $TOPIC.seed.doc

    done < "judgement/$CORP.topic.stemming.txt"

    rm -rf "$CORP".svm.fil
    rm "$CORP".df

    rm N

    # Generate LSI from tfdf
    # python clustering/doLSI.py --input=tfdf_oldreut --output=LSIVector/"$CORP".lsi.dump --mapping=LSIVector/"$CORP".mapping.dump --latent=200 --choice=entropy --normalization=yes

done
